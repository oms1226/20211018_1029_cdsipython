{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer['data'],\n",
    "                                                    cancer['target'],\n",
    "                                                    stratify=cancer['target'],\n",
    "                                                    random_state=0)\n",
    "cancer['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr),\n",
    "                         ('dt3', dt3), ('dt5', dt5)])\n",
    "\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr),\n",
    "                         ('dt3', dt3), ('dt5', dt5)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "VotingRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard Train Accuracy:98.12%\n",
      "hard Test Accuracy:95.10%\n",
      "\n",
      "soft Train Accuracy:99.53%\n",
      "soft Test Accuracy:95.80%\n",
      "\n",
      "knn1 Train Accuracy:94.60%\n",
      "knn1 Test Accuracy:91.61%\n",
      "\n",
      "knn2 Train Accuracy:95.77%\n",
      "knn2 Test Accuracy:91.61%\n",
      "\n",
      "lr Train Accuracy:96.71%\n",
      "lr Test Accuracy:93.71%\n",
      "\n",
      "dt3 Train Accuracy:97.65%\n",
      "dt3 Test Accuracy:93.01%\n",
      "\n",
      "dt5 Train Accuracy:100.00%\n",
      "dt5 Test Accuracy:93.01%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['hard', 'soft', 'knn1', 'knn2', 'lr', 'dt3', 'dt5']\n",
    "for idx, model in enumerate([hard, soft, knn1, knn2, lr, dt3, dt5]):\n",
    "    model.fit(x_train, y_train)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(x_train, y_train) * 100\n",
    "    test_score = model.score(x_test, y_test) * 100\n",
    "    print(f'{name} Train Accuracy:{train_score:.2f}%')\n",
    "    print(f'{name} Test Accuracy:{test_score:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.951048951048951)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=5).fit(x_train, y_train)\n",
    "model.score(x_train, y_train), model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.951048951048951)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier().fit(x_train, y_train)\n",
    "model.score(x_train, y_train), model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()), \n",
    "              ('gb', GradientBoostingClassifier())]\n",
    "\n",
    "model = StackingClassifier(estimators=estimators,\n",
    "                         final_estimator=LogisticRegression())\n",
    "\n",
    "model.fit(x_train, y_train).score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackingClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.3.3-py3-none-win_amd64.whl (95.2 MB)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.18.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:54:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.999999003030776, 0.7476326752660457)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "    \n",
    "boston = load_boston()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston['data'],\n",
    "                                                    boston['target'],\n",
    "                                                    random_state=0)\n",
    "model = xgb.XGBRegressor(objective ='reg:linear')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "p_train = model.predict(x_train)\n",
    "p_test = model.predict(x_test)\n",
    "\n",
    "r2_score(y_train, p_train), r2_score(y_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.1.1-py2.py3-none-win_amd64.whl (754 kB)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\anaconda3\\lib\\site-packages (from lightgbm) (0.22.1)\n",
      "Requirement already satisfied: wheel in c:\\anaconda3\\lib\\site-packages (from lightgbm) (0.34.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.18.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.14.1)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 973\n",
      "[LightGBM] [Info] Number of data points in the train set: 379, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 22.608707\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's l2: 70.5396\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's l2: 61.4369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's l2: 53.753\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's l2: 47.6561\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's l2: 42.6525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's l2: 38.518\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's l2: 35.5033\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's l2: 33.0258\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's l2: 31.2533\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's l2: 29.944\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's l2: 28.4314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's l2: 27.6605\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's l2: 26.7994\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's l2: 26.3312\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's l2: 25.3739\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's l2: 25.03\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's l2: 24.2976\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's l2: 24.0748\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's l2: 23.5555\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's l2: 23.5175\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's l2: 23.1308\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's l2: 23.2182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's l2: 23.3182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's l2: 23.0598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's l2: 23.1663\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's l2: 23.047\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's l2: 22.8929\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's l2: 22.935\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's l2: 22.8582\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's l2: 22.8969\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's l2: 22.9518\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's l2: 22.7715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's l2: 22.5838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's l2: 22.6132\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's l2: 22.515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's l2: 22.3831\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's l2: 22.2797\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's l2: 22.1626\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's l2: 22.0369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's l2: 21.9226\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's l2: 21.7859\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's l2: 21.7321\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's l2: 21.592\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's l2: 21.5128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's l2: 21.5581\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's l2: 21.4947\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's l2: 21.6217\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's l2: 21.578\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's l2: 21.6729\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's l2: 21.5881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's l2: 21.7236\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's l2: 21.4947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9524522112992748, 0.7369037475494296)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston['data'],\n",
    "                                                    boston['target'],\n",
    "                                                    random_state=0)\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "}\n",
    "\n",
    "model = lgb.train(params, lgb_train, valid_sets=lgb_eval,\n",
    "                  early_stopping_rounds=5)\n",
    "\n",
    "p_train = model.predict(x_train, num_iteration=model.best_iteration)\n",
    "p_test = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "\n",
    "r2_score(y_train, p_train), r2_score(y_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 세트 준비\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "\n",
    "# 데이터 분할\n",
    "\n",
    "\n",
    "# 모델 평가 (가장 좋은 Classification 모델을 찾아보세요.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_no_change=None,\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=0, subsample=1.0,\n",
       "                                                 tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.01, 0.01, 0.1],\n",
       "                         'max_depth': [3, 4, 5],\n",
       "                         'n_estimators': [100, 300, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "boston = load_boston()\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "params = {\n",
    "    'n_estimators' : [100, 300, 500],\n",
    "    'learning_rate' : [0.01, 0.01, 0.1],\n",
    "    'max_depth' : [3, 4, 5],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, params).fit(boston.data, boston.target)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085770</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>4.886555e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.622020</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.220861</td>\n",
       "      <td>0.325642</td>\n",
       "      <td>-0.175309</td>\n",
       "      <td>0.336265</td>\n",
       "      <td>0.310029</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.254120</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>9.536743e-08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.865449</td>\n",
       "      <td>0.691776</td>\n",
       "      <td>0.484630</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.622589</td>\n",
       "      <td>0.197722</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.421473</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>3.162980e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.762956</td>\n",
       "      <td>0.867336</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.535428</td>\n",
       "      <td>0.380540</td>\n",
       "      <td>0.656949</td>\n",
       "      <td>0.175110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.105722</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>4.886361e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.633338</td>\n",
       "      <td>0.626206</td>\n",
       "      <td>0.314555</td>\n",
       "      <td>0.374583</td>\n",
       "      <td>-0.252105</td>\n",
       "      <td>0.339315</td>\n",
       "      <td>0.322612</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.315756</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>1.907349e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.756735</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.656688</td>\n",
       "      <td>0.506602</td>\n",
       "      <td>0.120894</td>\n",
       "      <td>0.569621</td>\n",
       "      <td>0.246721</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.527382</td>\n",
       "      <td>0.010449</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>1.885443e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.768721</td>\n",
       "      <td>0.808021</td>\n",
       "      <td>0.693576</td>\n",
       "      <td>0.544797</td>\n",
       "      <td>0.222282</td>\n",
       "      <td>0.607479</td>\n",
       "      <td>0.212572</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.127469</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>9.066178e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.634823</td>\n",
       "      <td>0.557666</td>\n",
       "      <td>0.292459</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>-0.240186</td>\n",
       "      <td>0.324362</td>\n",
       "      <td>0.307677</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.379379</td>\n",
       "      <td>0.011713</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>4.892256e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.741062</td>\n",
       "      <td>0.762564</td>\n",
       "      <td>0.582336</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>0.519080</td>\n",
       "      <td>0.265290</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.619743</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>6.306003e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.753030</td>\n",
       "      <td>0.762199</td>\n",
       "      <td>0.622824</td>\n",
       "      <td>0.498162</td>\n",
       "      <td>0.105948</td>\n",
       "      <td>0.548433</td>\n",
       "      <td>0.241416</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.085970</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>3.990656e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.622020</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.220861</td>\n",
       "      <td>0.325642</td>\n",
       "      <td>-0.175309</td>\n",
       "      <td>0.336265</td>\n",
       "      <td>0.310029</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.255941</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>1.219436e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.865449</td>\n",
       "      <td>0.691776</td>\n",
       "      <td>0.484630</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.622589</td>\n",
       "      <td>0.197722</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.433441</td>\n",
       "      <td>0.007069</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.987551e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.762956</td>\n",
       "      <td>0.867336</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.535428</td>\n",
       "      <td>0.380540</td>\n",
       "      <td>0.656949</td>\n",
       "      <td>0.175110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.107306</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>3.988029e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.633338</td>\n",
       "      <td>0.626206</td>\n",
       "      <td>0.314555</td>\n",
       "      <td>0.374583</td>\n",
       "      <td>-0.252105</td>\n",
       "      <td>0.339315</td>\n",
       "      <td>0.322612</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.323933</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>2.604771e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.756735</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.656688</td>\n",
       "      <td>0.506602</td>\n",
       "      <td>0.120894</td>\n",
       "      <td>0.569621</td>\n",
       "      <td>0.246721</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.527595</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.990413e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.768721</td>\n",
       "      <td>0.808021</td>\n",
       "      <td>0.693576</td>\n",
       "      <td>0.544797</td>\n",
       "      <td>0.222282</td>\n",
       "      <td>0.607479</td>\n",
       "      <td>0.212572</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.125265</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>1.340243e-06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.634823</td>\n",
       "      <td>0.557666</td>\n",
       "      <td>0.292459</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>-0.240186</td>\n",
       "      <td>0.324362</td>\n",
       "      <td>0.307677</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.384167</td>\n",
       "      <td>0.010977</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>4.817301e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.741062</td>\n",
       "      <td>0.762564</td>\n",
       "      <td>0.582336</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>0.519080</td>\n",
       "      <td>0.265290</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.633102</td>\n",
       "      <td>0.011171</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.118323e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.753030</td>\n",
       "      <td>0.762199</td>\n",
       "      <td>0.622824</td>\n",
       "      <td>0.498162</td>\n",
       "      <td>0.105948</td>\n",
       "      <td>0.548433</td>\n",
       "      <td>0.241416</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.085371</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>4.969475e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.783812</td>\n",
       "      <td>0.857255</td>\n",
       "      <td>0.742070</td>\n",
       "      <td>0.570781</td>\n",
       "      <td>0.394882</td>\n",
       "      <td>0.669760</td>\n",
       "      <td>0.166581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.258713</td>\n",
       "      <td>0.007724</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>3.989221e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.784743</td>\n",
       "      <td>0.841977</td>\n",
       "      <td>0.750611</td>\n",
       "      <td>0.554167</td>\n",
       "      <td>0.389019</td>\n",
       "      <td>0.664103</td>\n",
       "      <td>0.168187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.427651</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>3.981591e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.779593</td>\n",
       "      <td>0.841031</td>\n",
       "      <td>0.755053</td>\n",
       "      <td>0.552954</td>\n",
       "      <td>0.379286</td>\n",
       "      <td>0.661583</td>\n",
       "      <td>0.171089</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.105313</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>4.885776e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.786304</td>\n",
       "      <td>0.824756</td>\n",
       "      <td>0.703891</td>\n",
       "      <td>0.579527</td>\n",
       "      <td>0.298256</td>\n",
       "      <td>0.638547</td>\n",
       "      <td>0.189767</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.318748</td>\n",
       "      <td>0.005759</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>2.336015e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.791083</td>\n",
       "      <td>0.826134</td>\n",
       "      <td>0.701349</td>\n",
       "      <td>0.554677</td>\n",
       "      <td>0.277191</td>\n",
       "      <td>0.630087</td>\n",
       "      <td>0.199827</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.527196</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>3.986599e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.794734</td>\n",
       "      <td>0.826199</td>\n",
       "      <td>0.700708</td>\n",
       "      <td>0.550373</td>\n",
       "      <td>0.272190</td>\n",
       "      <td>0.628841</td>\n",
       "      <td>0.202481</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.124866</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>1.168008e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.742366</td>\n",
       "      <td>0.770063</td>\n",
       "      <td>0.621733</td>\n",
       "      <td>0.534051</td>\n",
       "      <td>0.068540</td>\n",
       "      <td>0.547351</td>\n",
       "      <td>0.254008</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.376793</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.884415e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.740434</td>\n",
       "      <td>0.767800</td>\n",
       "      <td>0.625547</td>\n",
       "      <td>0.526456</td>\n",
       "      <td>0.061470</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.256307</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.624730</td>\n",
       "      <td>0.009723</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4.882857e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.740496</td>\n",
       "      <td>0.767871</td>\n",
       "      <td>0.625721</td>\n",
       "      <td>0.526112</td>\n",
       "      <td>0.060925</td>\n",
       "      <td>0.544225</td>\n",
       "      <td>0.256550</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.085770      0.001784         0.000598    4.886555e-04   \n",
       "1        0.254120      0.003796         0.000997    9.536743e-08   \n",
       "2        0.421473      0.006600         0.000997    3.162980e-07   \n",
       "3        0.105722      0.001900         0.000399    4.886361e-04   \n",
       "4        0.315756      0.004575         0.000997    1.907349e-07   \n",
       "5        0.527382      0.010449         0.001995    1.885443e-05   \n",
       "6        0.127469      0.004255         0.000993    9.066178e-06   \n",
       "7        0.379379      0.011713         0.001397    4.892256e-04   \n",
       "8        0.619743      0.010405         0.001995    6.306003e-04   \n",
       "9        0.085970      0.001589         0.000798    3.990656e-04   \n",
       "10       0.255941      0.004983         0.000997    1.219436e-06   \n",
       "11       0.433441      0.007069         0.001197    3.987551e-04   \n",
       "12       0.107306      0.001848         0.000798    3.988029e-04   \n",
       "13       0.323933      0.007188         0.000999    2.604771e-06   \n",
       "14       0.527595      0.011346         0.001197    3.990413e-04   \n",
       "15       0.125265      0.002943         0.000998    1.340243e-06   \n",
       "16       0.384167      0.010977         0.001602    4.817301e-04   \n",
       "17       0.633102      0.011171         0.002000    1.118323e-05   \n",
       "18       0.085371      0.001623         0.000406    4.969475e-04   \n",
       "19       0.258713      0.007724         0.000798    3.989221e-04   \n",
       "20       0.427651      0.007072         0.001196    3.981591e-04   \n",
       "21       0.105313      0.001626         0.000399    4.885776e-04   \n",
       "22       0.318748      0.005759         0.000997    2.336015e-07   \n",
       "23       0.527196      0.008657         0.001197    3.986599e-04   \n",
       "24       0.124866      0.001934         0.000997    1.168008e-07   \n",
       "25       0.376793      0.006320         0.001396    4.884415e-04   \n",
       "26       0.624730      0.009723         0.001396    4.882857e-04   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                 0.01               3                100   \n",
       "1                 0.01               3                300   \n",
       "2                 0.01               3                500   \n",
       "3                 0.01               4                100   \n",
       "4                 0.01               4                300   \n",
       "5                 0.01               4                500   \n",
       "6                 0.01               5                100   \n",
       "7                 0.01               5                300   \n",
       "8                 0.01               5                500   \n",
       "9                 0.01               3                100   \n",
       "10                0.01               3                300   \n",
       "11                0.01               3                500   \n",
       "12                0.01               4                100   \n",
       "13                0.01               4                300   \n",
       "14                0.01               4                500   \n",
       "15                0.01               5                100   \n",
       "16                0.01               5                300   \n",
       "17                0.01               5                500   \n",
       "18                 0.1               3                100   \n",
       "19                 0.1               3                300   \n",
       "20                 0.1               3                500   \n",
       "21                 0.1               4                100   \n",
       "22                 0.1               4                300   \n",
       "23                 0.1               4                500   \n",
       "24                 0.1               5                100   \n",
       "25                 0.1               5                300   \n",
       "26                 0.1               5                500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.622020   \n",
       "1   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.756358   \n",
       "2   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.762956   \n",
       "3   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.633338   \n",
       "4   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.756735   \n",
       "5   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.768721   \n",
       "6   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.634823   \n",
       "7   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.741062   \n",
       "8   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.753030   \n",
       "9   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.622020   \n",
       "10  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.756358   \n",
       "11  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.762956   \n",
       "12  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.633338   \n",
       "13  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.756735   \n",
       "14  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.768721   \n",
       "15  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.634823   \n",
       "16  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.741062   \n",
       "17  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.753030   \n",
       "18  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.783812   \n",
       "19  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.784743   \n",
       "20  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.779593   \n",
       "21  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.786304   \n",
       "22  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.791083   \n",
       "23  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.794734   \n",
       "24  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.742366   \n",
       "25  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.740434   \n",
       "26  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.740496   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.688112           0.220861           0.325642   \n",
       "1            0.865449           0.691776           0.484630   \n",
       "2            0.867336           0.738485           0.535428   \n",
       "3            0.626206           0.314555           0.374583   \n",
       "4            0.807186           0.656688           0.506602   \n",
       "5            0.808021           0.693576           0.544797   \n",
       "6            0.557666           0.292459           0.377049   \n",
       "7            0.762564           0.582336           0.477830   \n",
       "8            0.762199           0.622824           0.498162   \n",
       "9            0.688112           0.220861           0.325642   \n",
       "10           0.865449           0.691776           0.484630   \n",
       "11           0.867336           0.738485           0.535428   \n",
       "12           0.626206           0.314555           0.374583   \n",
       "13           0.807186           0.656688           0.506602   \n",
       "14           0.808021           0.693576           0.544797   \n",
       "15           0.557666           0.292459           0.377049   \n",
       "16           0.762564           0.582336           0.477830   \n",
       "17           0.762199           0.622824           0.498162   \n",
       "18           0.857255           0.742070           0.570781   \n",
       "19           0.841977           0.750611           0.554167   \n",
       "20           0.841031           0.755053           0.552954   \n",
       "21           0.824756           0.703891           0.579527   \n",
       "22           0.826134           0.701349           0.554677   \n",
       "23           0.826199           0.700708           0.550373   \n",
       "24           0.770063           0.621733           0.534051   \n",
       "25           0.767800           0.625547           0.526456   \n",
       "26           0.767871           0.625721           0.526112   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           -0.175309         0.336265        0.310029               24  \n",
       "1            0.314734         0.622589        0.197722                9  \n",
       "2            0.380540         0.656949        0.175110                4  \n",
       "3           -0.252105         0.339315        0.322612               22  \n",
       "4            0.120894         0.569621        0.246721               13  \n",
       "5            0.222282         0.607479        0.212572               11  \n",
       "6           -0.240186         0.324362        0.307677               26  \n",
       "7            0.031606         0.519080        0.265290               20  \n",
       "8            0.105948         0.548433        0.241416               15  \n",
       "9           -0.175309         0.336265        0.310029               24  \n",
       "10           0.314734         0.622589        0.197722                9  \n",
       "11           0.380540         0.656949        0.175110                4  \n",
       "12          -0.252105         0.339315        0.322612               22  \n",
       "13           0.120894         0.569621        0.246721               13  \n",
       "14           0.222282         0.607479        0.212572               11  \n",
       "15          -0.240186         0.324362        0.307677               26  \n",
       "16           0.031606         0.519080        0.265290               20  \n",
       "17           0.105948         0.548433        0.241416               15  \n",
       "18           0.394882         0.669760        0.166581                1  \n",
       "19           0.389019         0.664103        0.168187                2  \n",
       "20           0.379286         0.661583        0.171089                3  \n",
       "21           0.298256         0.638547        0.189767                6  \n",
       "22           0.277191         0.630087        0.199827                7  \n",
       "23           0.272190         0.628841        0.202481                8  \n",
       "24           0.068540         0.547351        0.254008               17  \n",
       "25           0.061470         0.544341        0.256307               18  \n",
       "26           0.060925         0.544225        0.256550               19  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "report = pd.DataFrame(gs.cv_results_)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6697600256867121"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=0, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
