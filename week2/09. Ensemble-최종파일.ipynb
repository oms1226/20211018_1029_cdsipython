{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유방암인지 일반 종양인지 데이터 분류\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Bunch 데이터 형태 \n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# 데이터 분할 진행 (데이터 나오는 순서 중요)\n",
    "# stratify = 레이블이 범주형일때만 사용 가능함 > 층화추출 > 범주별로 데이터를 분리 (범주 비율이 train, test 가 동일해진다)\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer['data'],\n",
    "                                                    cancer['target'],\n",
    "                                                    stratify=cancer['target'], #층화추출 진행 (분류별 문제에서는 범주 갯수 고려)\n",
    "                                                    random_state=0)\n",
    "cancer['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 모델 하이퍼파라메터를 따로 줄 수 있음. 보팅에 참여할 분류기를 따로 만들 수 있다.\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "dt3 = DecisionTreeClassifier(max_depth=3)\n",
    "dt5 = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VotingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# '모델 이름', 모델 변수를 만들어서 넣어줌 \n",
    "# models = [('knn1', knn1)]\n",
    "hard = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr),\n",
    "                         ('dt3', dt3), ('dt5', dt5)], voting='hard').fit(x_train, y_train) # 모델별로 예측된 범주를 집계 \n",
    "\n",
    "soft = VotingClassifier([('knn1', knn1), ('knn2', knn2), ('lr', lr),\n",
    "                         ('dt3', dt3), ('dt5', dt5)], voting='soft').fit(x_train, y_train) # 모델별로 예측된 확률을 집계 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9812206572769953, 0.951048951048951)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard.score(x_train, y_train), hard.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9953051643192489, 0.951048951048951)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft.score(x_train, y_train), soft.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting (hard, soft) + 개별 예측 모형의 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard Train Accuracy:98.12%\n",
      "hard Test Accuracy:95.10%\n",
      "\n",
      "soft Train Accuracy:99.53%\n",
      "soft Test Accuracy:95.80%\n",
      "\n",
      "knn1 Train Accuracy:94.60%\n",
      "knn1 Test Accuracy:91.61%\n",
      "\n",
      "knn2 Train Accuracy:95.77%\n",
      "knn2 Test Accuracy:91.61%\n",
      "\n",
      "lr Train Accuracy:96.71%\n",
      "lr Test Accuracy:93.71%\n",
      "\n",
      "dt3 Train Accuracy:97.65%\n",
      "dt3 Test Accuracy:91.61%\n",
      "\n",
      "dt5 Train Accuracy:100.00%\n",
      "dt5 Test Accuracy:90.91%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['hard', 'soft', 'knn1', 'knn2', 'lr', 'dt3', 'dt5']\n",
    "for idx, model in enumerate([hard, soft, knn1, knn2, lr, dt3, dt5]):\n",
    "    model.fit(x_train, y_train)\n",
    "    name = names[idx]\n",
    "    train_score = model.score(x_train, y_train) * 100\n",
    "    test_score = model.score(x_test, y_test) * 100\n",
    "    print(f'{name} Train Accuracy:{train_score:.2f}%')\n",
    "    print(f'{name} Test Accuracy:{test_score:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._voting.VotingRegressor"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VotingRegressor 동일함 \n",
    "from sklearn.ensemble import VotingRegressor\n",
    "VotingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging - RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9976525821596244, 0.9440559440559441)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=5).fit(x_train, y_train)\n",
    "model.score(x_train, y_train), model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.951048951048951)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_estimators\n",
    "# - 분류기를 몇 개 만들 것인가? (Decision Tree) 많으면 많을수록 좋은게 아니다. 일정 수준까지만 올라가고 일정 시점 이후에는 성능이 안좋아짐 \n",
    "# max_depth : DT의 최대 깊이를 어느 정도로 지정하는가? \n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5).fit(x_train, y_train)\n",
    "model.score(x_train, y_train), model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02804731, 0.0126832 , 0.04046199, 0.05126162, 0.00524703,\n",
       "       0.01607026, 0.02453329, 0.13955595, 0.00169701, 0.00219765,\n",
       "       0.01311099, 0.00570037, 0.01412069, 0.03366997, 0.00378678,\n",
       "       0.00352711, 0.00499939, 0.00126242, 0.00232875, 0.00297676,\n",
       "       0.11698535, 0.02007215, 0.10738984, 0.15377893, 0.00713619,\n",
       "       0.01298514, 0.03531582, 0.12633394, 0.00400643, 0.0087577 ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_ # RandomForest 변수중요도 자잘하게 나온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff05e1ef780>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "fi = pd.Series(model.feature_importances_, index=cancer[\"feature_names\"])\n",
    "fi.sort_values().plot(kind='barh')#영향도를 전체적으로 보고 싶다면, 랜덤포레스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting - GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9370629370629371)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=4).fit(x_train, y_train)\n",
    "model.score(x_train, y_train), model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.05700794e-06, 2.35468896e-02, 1.54381015e-07, 9.63320614e-05,\n",
       "       3.01929958e-03, 3.74141966e-12, 1.08300014e-03, 4.91141824e-02,\n",
       "       6.06624057e-03, 1.01451819e-09, 2.65536158e-03, 1.87644883e-03,\n",
       "       1.50036377e-03, 1.00025109e-02, 9.27060611e-04, 3.14883353e-06,\n",
       "       9.25731983e-04, 1.85469440e-02, 6.95753455e-04, 8.04811119e-04,\n",
       "       1.56237567e-02, 4.11526087e-02, 7.30424726e-01, 1.12239684e-02,\n",
       "       2.68204354e-03, 2.05007845e-08, 2.41249774e-04, 7.59521607e-02,\n",
       "       1.09994379e-03, 7.33229987e-04])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_ # 특정한 계수가 높게 나온다.  한두개 정도만 나오는 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff05e2b4e48>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi = pd.Series(model.feature_importances_, index=cancer[\"feature_names\"])\n",
    "fi.sort_values().plot(kind='barh')#젤중요한 피쳐만 확인하고 싶다면 GrandientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(boston[\"data\"], boston[\"target\"], \n",
    "                                                       random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7697699488741149, 0.635463843320211)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression().fit(x_train2, y_train2)\n",
    "model.score(x_train2, y_train2), model.score(x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.983979204210904, 0.7943785634234231)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor#회귀에 대해 overfitting 가능성이 높음\n",
    "model = RandomForestRegressor().fit(x_train2, y_train2)\n",
    "model.score(x_train2, y_train2), model.score(x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9829864654169255, 0.8255093706526744)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor().fit(x_train2, y_train2)\n",
    "model.score(x_train2, y_train2), model.score(x_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff05e091b00>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(model.feature_importances_, index=boston['feature_names']).sort_values().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid-Search - 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingClassifier(random_state=0),\n",
       "             param_grid={'learning_rate': [0.01, 0.01, 0.1],\n",
       "                         'max_depth': [3, 4, 5], 'max_features': [10, 20]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "# CV 교차검증 -> 데이터를 동일한 크기로 분할(Fold) -> 각 Fold를 Test로 지정하여 여러번 실험\n",
    "from sklearn.model_selection import GridSearchCV # CV : 교차검증 수행 , 값이 높은 모델을 Best로 선정함 \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Bunch 데이터 형태 \n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Baseline 모델 \n",
    "model = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# 주어지는 파라메터에 따라 속도가 매우 오래 걸릴 수 있다.\n",
    "params = {\n",
    "    'learning_rate' : [0.01, 0.01, 0.1], # 앞선 모델의 오류를 얼만큼 반영 할 것인지?\n",
    "    'max_depth' : [3, 4, 5], # DT의 최대 깊이 \n",
    "    'max_features' : [10, 20] # 최대 사용 가능한 특성의 개수\n",
    "}  \n",
    "\n",
    "# GridSearchCV 수행시 데이터를 train, test로 분할하지 않아도 됨\n",
    "gs = GridSearchCV(model, params).fit(cancer.data, cancer.target)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.109801</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.783812</td>\n",
       "      <td>0.857255</td>\n",
       "      <td>0.742070</td>\n",
       "      <td>0.570781</td>\n",
       "      <td>0.394882</td>\n",
       "      <td>0.669760</td>\n",
       "      <td>0.166581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.328022</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.784743</td>\n",
       "      <td>0.841977</td>\n",
       "      <td>0.750611</td>\n",
       "      <td>0.554167</td>\n",
       "      <td>0.389019</td>\n",
       "      <td>0.664103</td>\n",
       "      <td>0.168187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.547035</td>\n",
       "      <td>0.008194</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.779593</td>\n",
       "      <td>0.841031</td>\n",
       "      <td>0.755053</td>\n",
       "      <td>0.552954</td>\n",
       "      <td>0.379286</td>\n",
       "      <td>0.661583</td>\n",
       "      <td>0.171089</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.545840</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.762956</td>\n",
       "      <td>0.867336</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.535428</td>\n",
       "      <td>0.380540</td>\n",
       "      <td>0.656949</td>\n",
       "      <td>0.175110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.547120</td>\n",
       "      <td>0.008022</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.762956</td>\n",
       "      <td>0.867336</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.535428</td>\n",
       "      <td>0.380540</td>\n",
       "      <td>0.656949</td>\n",
       "      <td>0.175110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.134149</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.786304</td>\n",
       "      <td>0.824756</td>\n",
       "      <td>0.703891</td>\n",
       "      <td>0.579527</td>\n",
       "      <td>0.298256</td>\n",
       "      <td>0.638547</td>\n",
       "      <td>0.189767</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.402467</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.791083</td>\n",
       "      <td>0.826134</td>\n",
       "      <td>0.701348</td>\n",
       "      <td>0.554677</td>\n",
       "      <td>0.277191</td>\n",
       "      <td>0.630087</td>\n",
       "      <td>0.199827</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.670865</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.794082</td>\n",
       "      <td>0.826204</td>\n",
       "      <td>0.700705</td>\n",
       "      <td>0.550373</td>\n",
       "      <td>0.272191</td>\n",
       "      <td>0.628711</td>\n",
       "      <td>0.202375</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328283</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.865449</td>\n",
       "      <td>0.691776</td>\n",
       "      <td>0.484630</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.622589</td>\n",
       "      <td>0.197722</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.328399</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.865449</td>\n",
       "      <td>0.691776</td>\n",
       "      <td>0.484630</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.622589</td>\n",
       "      <td>0.197722</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.665433</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.768721</td>\n",
       "      <td>0.808021</td>\n",
       "      <td>0.693576</td>\n",
       "      <td>0.544797</td>\n",
       "      <td>0.224560</td>\n",
       "      <td>0.607935</td>\n",
       "      <td>0.211747</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.666222</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.768721</td>\n",
       "      <td>0.808021</td>\n",
       "      <td>0.693576</td>\n",
       "      <td>0.544797</td>\n",
       "      <td>0.224560</td>\n",
       "      <td>0.607935</td>\n",
       "      <td>0.211747</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.401325</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.756735</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.656688</td>\n",
       "      <td>0.506602</td>\n",
       "      <td>0.123035</td>\n",
       "      <td>0.570049</td>\n",
       "      <td>0.245943</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400393</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.756735</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.656688</td>\n",
       "      <td>0.506602</td>\n",
       "      <td>0.123035</td>\n",
       "      <td>0.570049</td>\n",
       "      <td>0.245943</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.158149</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.742419</td>\n",
       "      <td>0.769675</td>\n",
       "      <td>0.626869</td>\n",
       "      <td>0.534051</td>\n",
       "      <td>0.078034</td>\n",
       "      <td>0.550210</td>\n",
       "      <td>0.250678</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.782538</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.753964</td>\n",
       "      <td>0.763259</td>\n",
       "      <td>0.622998</td>\n",
       "      <td>0.498162</td>\n",
       "      <td>0.105823</td>\n",
       "      <td>0.548841</td>\n",
       "      <td>0.241819</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.785942</td>\n",
       "      <td>0.013528</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.753964</td>\n",
       "      <td>0.763259</td>\n",
       "      <td>0.622998</td>\n",
       "      <td>0.498162</td>\n",
       "      <td>0.105823</td>\n",
       "      <td>0.548841</td>\n",
       "      <td>0.241819</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.474778</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.740558</td>\n",
       "      <td>0.767554</td>\n",
       "      <td>0.630651</td>\n",
       "      <td>0.526032</td>\n",
       "      <td>0.071061</td>\n",
       "      <td>0.547171</td>\n",
       "      <td>0.253007</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.789560</td>\n",
       "      <td>0.013747</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.767495</td>\n",
       "      <td>0.630505</td>\n",
       "      <td>0.525423</td>\n",
       "      <td>0.070617</td>\n",
       "      <td>0.546923</td>\n",
       "      <td>0.253167</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.471141</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.741932</td>\n",
       "      <td>0.763737</td>\n",
       "      <td>0.582341</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.519629</td>\n",
       "      <td>0.265394</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.472603</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.741932</td>\n",
       "      <td>0.763737</td>\n",
       "      <td>0.582341</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.519629</td>\n",
       "      <td>0.265394</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.134940</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.633338</td>\n",
       "      <td>0.626206</td>\n",
       "      <td>0.314555</td>\n",
       "      <td>0.374583</td>\n",
       "      <td>-0.250098</td>\n",
       "      <td>0.339717</td>\n",
       "      <td>0.321876</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135954</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.633338</td>\n",
       "      <td>0.626206</td>\n",
       "      <td>0.314555</td>\n",
       "      <td>0.374583</td>\n",
       "      <td>-0.250098</td>\n",
       "      <td>0.339717</td>\n",
       "      <td>0.321876</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.110356</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.622020</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.220861</td>\n",
       "      <td>0.325642</td>\n",
       "      <td>-0.175309</td>\n",
       "      <td>0.336265</td>\n",
       "      <td>0.310029</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.114536</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.622020</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.220861</td>\n",
       "      <td>0.325642</td>\n",
       "      <td>-0.175309</td>\n",
       "      <td>0.336265</td>\n",
       "      <td>0.310029</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.158078</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.634855</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>0.290091</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>-0.234089</td>\n",
       "      <td>0.325673</td>\n",
       "      <td>0.305927</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.158405</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.634855</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>0.290091</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>-0.234089</td>\n",
       "      <td>0.325673</td>\n",
       "      <td>0.305927</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "18       0.109801      0.001725         0.000650        0.000023   \n",
       "19       0.328022      0.004611         0.001003        0.000013   \n",
       "20       0.547035      0.008194         0.001282        0.000024   \n",
       "2        0.545840      0.007736         0.001223        0.000039   \n",
       "11       0.547120      0.008022         0.001219        0.000031   \n",
       "21       0.134149      0.001965         0.000754        0.000022   \n",
       "22       0.402467      0.006345         0.001191        0.000022   \n",
       "23       0.670865      0.008965         0.001558        0.000042   \n",
       "1        0.328283      0.005274         0.000947        0.000041   \n",
       "10       0.328399      0.005775         0.000939        0.000020   \n",
       "5        0.665433      0.010462         0.001522        0.000061   \n",
       "14       0.666222      0.010422         0.001502        0.000046   \n",
       "13       0.401325      0.005160         0.001164        0.000077   \n",
       "4        0.400393      0.006744         0.001178        0.000044   \n",
       "24       0.158149      0.002636         0.000837        0.000031   \n",
       "8        0.782538      0.013632         0.001951        0.000090   \n",
       "17       0.785942      0.013528         0.001995        0.000091   \n",
       "25       0.474778      0.006670         0.001383        0.000032   \n",
       "26       0.789560      0.013747         0.001845        0.000024   \n",
       "7        0.471141      0.008411         0.001430        0.000077   \n",
       "16       0.472603      0.007729         0.001466        0.000086   \n",
       "12       0.134940      0.002151         0.000714        0.000030   \n",
       "3        0.135954      0.004044         0.000706        0.000030   \n",
       "9        0.110356      0.001655         0.000638        0.000028   \n",
       "0        0.114536      0.005468         0.000666        0.000040   \n",
       "15       0.158078      0.002936         0.000783        0.000057   \n",
       "6        0.158405      0.003741         0.000815        0.000017   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "18                 0.1               3                100   \n",
       "19                 0.1               3                300   \n",
       "20                 0.1               3                500   \n",
       "2                 0.01               3                500   \n",
       "11                0.01               3                500   \n",
       "21                 0.1               4                100   \n",
       "22                 0.1               4                300   \n",
       "23                 0.1               4                500   \n",
       "1                 0.01               3                300   \n",
       "10                0.01               3                300   \n",
       "5                 0.01               4                500   \n",
       "14                0.01               4                500   \n",
       "13                0.01               4                300   \n",
       "4                 0.01               4                300   \n",
       "24                 0.1               5                100   \n",
       "8                 0.01               5                500   \n",
       "17                0.01               5                500   \n",
       "25                 0.1               5                300   \n",
       "26                 0.1               5                500   \n",
       "7                 0.01               5                300   \n",
       "16                0.01               5                300   \n",
       "12                0.01               4                100   \n",
       "3                 0.01               4                100   \n",
       "9                 0.01               3                100   \n",
       "0                 0.01               3                100   \n",
       "15                0.01               5                100   \n",
       "6                 0.01               5                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "18  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.783812   \n",
       "19  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.784743   \n",
       "20  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.779593   \n",
       "2   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.762956   \n",
       "11  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.762956   \n",
       "21  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.786304   \n",
       "22  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.791083   \n",
       "23  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.794082   \n",
       "1   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.756358   \n",
       "10  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.756358   \n",
       "5   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.768721   \n",
       "14  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.768721   \n",
       "13  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.756735   \n",
       "4   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.756735   \n",
       "24  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.742419   \n",
       "8   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.753964   \n",
       "17  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.753964   \n",
       "25  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.740558   \n",
       "26  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.740573   \n",
       "7   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.741932   \n",
       "16  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.741932   \n",
       "12  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.633338   \n",
       "3   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.633338   \n",
       "9   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.622020   \n",
       "0   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.622020   \n",
       "15  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.634855   \n",
       "6   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.634855   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "18           0.857255           0.742070           0.570781   \n",
       "19           0.841977           0.750611           0.554167   \n",
       "20           0.841031           0.755053           0.552954   \n",
       "2            0.867336           0.738485           0.535428   \n",
       "11           0.867336           0.738485           0.535428   \n",
       "21           0.824756           0.703891           0.579527   \n",
       "22           0.826134           0.701348           0.554677   \n",
       "23           0.826204           0.700705           0.550373   \n",
       "1            0.865449           0.691776           0.484630   \n",
       "10           0.865449           0.691776           0.484630   \n",
       "5            0.808021           0.693576           0.544797   \n",
       "14           0.808021           0.693576           0.544797   \n",
       "13           0.807186           0.656688           0.506602   \n",
       "4            0.807186           0.656688           0.506602   \n",
       "24           0.769675           0.626869           0.534051   \n",
       "8            0.763259           0.622998           0.498162   \n",
       "17           0.763259           0.622998           0.498162   \n",
       "25           0.767554           0.630651           0.526032   \n",
       "26           0.767495           0.630505           0.525423   \n",
       "7            0.763737           0.582341           0.477830   \n",
       "16           0.763737           0.582341           0.477830   \n",
       "12           0.626206           0.314555           0.374583   \n",
       "3            0.626206           0.314555           0.374583   \n",
       "9            0.688112           0.220861           0.325642   \n",
       "0            0.688112           0.220861           0.325642   \n",
       "15           0.560458           0.290091           0.377049   \n",
       "6            0.560458           0.290091           0.377049   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "18           0.394882         0.669760        0.166581                1  \n",
       "19           0.389019         0.664103        0.168187                2  \n",
       "20           0.379286         0.661583        0.171089                3  \n",
       "2            0.380540         0.656949        0.175110                4  \n",
       "11           0.380540         0.656949        0.175110                4  \n",
       "21           0.298256         0.638547        0.189767                6  \n",
       "22           0.277191         0.630087        0.199827                7  \n",
       "23           0.272191         0.628711        0.202375                8  \n",
       "1            0.314734         0.622589        0.197722                9  \n",
       "10           0.314734         0.622589        0.197722                9  \n",
       "5            0.224560         0.607935        0.211747               11  \n",
       "14           0.224560         0.607935        0.211747               11  \n",
       "13           0.123035         0.570049        0.245943               13  \n",
       "4            0.123035         0.570049        0.245943               13  \n",
       "24           0.078034         0.550210        0.250678               15  \n",
       "8            0.105823         0.548841        0.241819               16  \n",
       "17           0.105823         0.548841        0.241819               16  \n",
       "25           0.071061         0.547171        0.253007               18  \n",
       "26           0.070617         0.546923        0.253167               19  \n",
       "7            0.032308         0.519629        0.265394               20  \n",
       "16           0.032308         0.519629        0.265394               20  \n",
       "12          -0.250098         0.339717        0.321876               22  \n",
       "3           -0.250098         0.339717        0.321876               22  \n",
       "9           -0.175309         0.336265        0.310029               24  \n",
       "0           -0.175309         0.336265        0.310029               24  \n",
       "15          -0.234089         0.325673        0.305927               26  \n",
       "6           -0.234089         0.325673        0.305927               26  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values('rank_test_score')#rank이므로 작을수록 좋은것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_features=10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier(**gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid-Search - 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(random_state=0),\n",
       "             param_grid={'learning_rate': [0.01, 0.01, 0.1],\n",
       "                         'max_depth': [3, 4, 5], 'max_features': [7, 10],\n",
       "                         'n_estimators': [100, 300, 500]},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "# CV 교차검증 -> 데이터를 동일한 크기로 분할(Fold) -> 각 Fold를 Test로 지정하여 여러번 실험\n",
    "from sklearn.model_selection import GridSearchCV # CV : 교차검증 수행 , 값이 높은 모델을 Best로 선정함 \n",
    "# 회귀모델에서는 MAE, MSE, RMSE 사용함. 낮을수록 좋음 \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "# Baseline 모델 \n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "# 주어지는 파라메터에 따라 속도가 매우 오래 걸릴 수 있다.\n",
    "params = {\n",
    "    'n_estimators' : [100, 300, 500], # 분류기의 개수 \n",
    "    'learning_rate' : [0.01, 0.01, 0.1], # 앞선 모델의 오류를 얼만큼 반영 할 것인지?\n",
    "    'max_depth' : [3, 4, 5], # DT의 최대 깊이 \n",
    "    'max_features' : [7, 10] # 최대 사용 가능한 특성의 개수\n",
    "}  \n",
    "\n",
    "# GridSearchCV 수행시 데이터를 train, test로 분할하지 않아도 됨\n",
    "# 회귀모델 사용시 이것을 써야 된다!\n",
    "# - scoring='neg_mean_absolute_error' : MAE가 낮을 수록 좋은 모델 선택\n",
    "#           'neg_mean_squared_error' : MSE가 낮은 수록 좋은 모델 선택\n",
    "# 결과는 마이너스가 나올텐데 여기에 * -1 해주면 된다. (부호 무시해도 됨)\n",
    "gs = GridSearchCV(model, params, scoring='neg_mean_absolute_error').fit(boston.data, boston.target)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074008</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-2.991279</td>\n",
       "      <td>-3.838458</td>\n",
       "      <td>-5.163388</td>\n",
       "      <td>-5.081986</td>\n",
       "      <td>-4.457233</td>\n",
       "      <td>-4.306469</td>\n",
       "      <td>0.813293</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.218407</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-2.313580</td>\n",
       "      <td>-2.595349</td>\n",
       "      <td>-3.508240</td>\n",
       "      <td>-3.964360</td>\n",
       "      <td>-3.154779</td>\n",
       "      <td>-3.107262</td>\n",
       "      <td>0.598272</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.363354</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-2.274481</td>\n",
       "      <td>-2.588614</td>\n",
       "      <td>-3.219857</td>\n",
       "      <td>-3.723926</td>\n",
       "      <td>-2.947703</td>\n",
       "      <td>-2.950916</td>\n",
       "      <td>0.501739</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093037</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-2.976407</td>\n",
       "      <td>-3.804186</td>\n",
       "      <td>-5.460877</td>\n",
       "      <td>-5.095924</td>\n",
       "      <td>-4.421125</td>\n",
       "      <td>-4.351704</td>\n",
       "      <td>0.892207</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276259</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'max_f...</td>\n",
       "      <td>-2.293343</td>\n",
       "      <td>-2.539757</td>\n",
       "      <td>-3.692916</td>\n",
       "      <td>-3.890901</td>\n",
       "      <td>-3.124648</td>\n",
       "      <td>-3.108313</td>\n",
       "      <td>0.623202</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.074008      0.001039         0.000653        0.000031   \n",
       "1       0.218407      0.002764         0.001002        0.000075   \n",
       "2       0.363354      0.006620         0.001260        0.000053   \n",
       "3       0.093037      0.001561         0.000625        0.000017   \n",
       "4       0.276259      0.004875         0.000969        0.000036   \n",
       "\n",
       "  param_learning_rate param_max_depth param_max_features param_n_estimators  \\\n",
       "0                0.01               3                  7                100   \n",
       "1                0.01               3                  7                300   \n",
       "2                0.01               3                  7                500   \n",
       "3                0.01               3                 10                100   \n",
       "4                0.01               3                 10                300   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'learning_rate': 0.01, 'max_depth': 3, 'max_f...          -2.991279   \n",
       "1  {'learning_rate': 0.01, 'max_depth': 3, 'max_f...          -2.313580   \n",
       "2  {'learning_rate': 0.01, 'max_depth': 3, 'max_f...          -2.274481   \n",
       "3  {'learning_rate': 0.01, 'max_depth': 3, 'max_f...          -2.976407   \n",
       "4  {'learning_rate': 0.01, 'max_depth': 3, 'max_f...          -2.293343   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0          -3.838458          -5.163388          -5.081986          -4.457233   \n",
       "1          -2.595349          -3.508240          -3.964360          -3.154779   \n",
       "2          -2.588614          -3.219857          -3.723926          -2.947703   \n",
       "3          -3.804186          -5.460877          -5.095924          -4.421125   \n",
       "4          -2.539757          -3.692916          -3.890901          -3.124648   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0        -4.306469        0.813293               51  \n",
       "1        -3.107262        0.598272               37  \n",
       "2        -2.950916        0.501739               19  \n",
       "3        -4.351704        0.892207               53  \n",
       "4        -3.108313        0.623202               39  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.511652</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'max_fe...</td>\n",
       "      <td>-2.165439</td>\n",
       "      <td>-2.822227</td>\n",
       "      <td>-2.906266</td>\n",
       "      <td>-3.459570</td>\n",
       "      <td>-2.988546</td>\n",
       "      <td>-2.868410</td>\n",
       "      <td>0.415123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.103045</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'max_fe...</td>\n",
       "      <td>-2.184135</td>\n",
       "      <td>-2.794347</td>\n",
       "      <td>-2.933148</td>\n",
       "      <td>-3.458599</td>\n",
       "      <td>-2.973726</td>\n",
       "      <td>-2.868791</td>\n",
       "      <td>0.409224</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.306944</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'max_fe...</td>\n",
       "      <td>-2.167164</td>\n",
       "      <td>-2.820053</td>\n",
       "      <td>-2.908010</td>\n",
       "      <td>-3.460485</td>\n",
       "      <td>-2.988572</td>\n",
       "      <td>-2.868857</td>\n",
       "      <td>0.414884</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.511895</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'max_f...</td>\n",
       "      <td>-2.135044</td>\n",
       "      <td>-2.695517</td>\n",
       "      <td>-3.063603</td>\n",
       "      <td>-3.483198</td>\n",
       "      <td>-2.996440</td>\n",
       "      <td>-2.874761</td>\n",
       "      <td>0.447207</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.511940</td>\n",
       "      <td>0.009773</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'max_f...</td>\n",
       "      <td>-2.135044</td>\n",
       "      <td>-2.695517</td>\n",
       "      <td>-3.063603</td>\n",
       "      <td>-3.483198</td>\n",
       "      <td>-2.996440</td>\n",
       "      <td>-2.874761</td>\n",
       "      <td>0.447207</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.092116</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'max_fe...</td>\n",
       "      <td>-2.157122</td>\n",
       "      <td>-2.745370</td>\n",
       "      <td>-3.463629</td>\n",
       "      <td>-3.353399</td>\n",
       "      <td>-2.763140</td>\n",
       "      <td>-2.896532</td>\n",
       "      <td>0.472799</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.436525</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'max_f...</td>\n",
       "      <td>-2.208418</td>\n",
       "      <td>-2.743499</td>\n",
       "      <td>-3.130612</td>\n",
       "      <td>-3.495194</td>\n",
       "      <td>-2.915315</td>\n",
       "      <td>-2.898608</td>\n",
       "      <td>0.426718</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.434484</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'max_f...</td>\n",
       "      <td>-2.208418</td>\n",
       "      <td>-2.743499</td>\n",
       "      <td>-3.130612</td>\n",
       "      <td>-3.495194</td>\n",
       "      <td>-2.915315</td>\n",
       "      <td>-2.898608</td>\n",
       "      <td>0.426718</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.072141</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'max_fe...</td>\n",
       "      <td>-2.179902</td>\n",
       "      <td>-2.833312</td>\n",
       "      <td>-3.016203</td>\n",
       "      <td>-3.629251</td>\n",
       "      <td>-2.844869</td>\n",
       "      <td>-2.900707</td>\n",
       "      <td>0.462890</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.361646</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'max_fe...</td>\n",
       "      <td>-2.231168</td>\n",
       "      <td>-2.943253</td>\n",
       "      <td>-2.877771</td>\n",
       "      <td>-3.710966</td>\n",
       "      <td>-2.777924</td>\n",
       "      <td>-2.908217</td>\n",
       "      <td>0.473695</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "50       0.511652      0.007486         0.001822        0.000030   \n",
       "48       0.103045      0.001578         0.000765        0.000032   \n",
       "49       0.306944      0.004647         0.001352        0.000027   \n",
       "32       0.511895      0.007820         0.002103        0.000100   \n",
       "14       0.511940      0.009773         0.002150        0.000054   \n",
       "39       0.092116      0.001340         0.000616        0.000029   \n",
       "26       0.436525      0.007817         0.001645        0.000075   \n",
       "8        0.434484      0.006887         0.001649        0.000041   \n",
       "36       0.072141      0.001352         0.000569        0.000007   \n",
       "38       0.361646      0.007437         0.001224        0.000026   \n",
       "\n",
       "   param_learning_rate param_max_depth param_max_features param_n_estimators  \\\n",
       "50                 0.1               5                  7                500   \n",
       "48                 0.1               5                  7                100   \n",
       "49                 0.1               5                  7                300   \n",
       "32                0.01               5                  7                500   \n",
       "14                0.01               5                  7                500   \n",
       "39                 0.1               3                 10                100   \n",
       "26                0.01               4                  7                500   \n",
       "8                 0.01               4                  7                500   \n",
       "36                 0.1               3                  7                100   \n",
       "38                 0.1               3                  7                500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "50  {'learning_rate': 0.1, 'max_depth': 5, 'max_fe...          -2.165439   \n",
       "48  {'learning_rate': 0.1, 'max_depth': 5, 'max_fe...          -2.184135   \n",
       "49  {'learning_rate': 0.1, 'max_depth': 5, 'max_fe...          -2.167164   \n",
       "32  {'learning_rate': 0.01, 'max_depth': 5, 'max_f...          -2.135044   \n",
       "14  {'learning_rate': 0.01, 'max_depth': 5, 'max_f...          -2.135044   \n",
       "39  {'learning_rate': 0.1, 'max_depth': 3, 'max_fe...          -2.157122   \n",
       "26  {'learning_rate': 0.01, 'max_depth': 4, 'max_f...          -2.208418   \n",
       "8   {'learning_rate': 0.01, 'max_depth': 4, 'max_f...          -2.208418   \n",
       "36  {'learning_rate': 0.1, 'max_depth': 3, 'max_fe...          -2.179902   \n",
       "38  {'learning_rate': 0.1, 'max_depth': 3, 'max_fe...          -2.231168   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "50          -2.822227          -2.906266          -3.459570   \n",
       "48          -2.794347          -2.933148          -3.458599   \n",
       "49          -2.820053          -2.908010          -3.460485   \n",
       "32          -2.695517          -3.063603          -3.483198   \n",
       "14          -2.695517          -3.063603          -3.483198   \n",
       "39          -2.745370          -3.463629          -3.353399   \n",
       "26          -2.743499          -3.130612          -3.495194   \n",
       "8           -2.743499          -3.130612          -3.495194   \n",
       "36          -2.833312          -3.016203          -3.629251   \n",
       "38          -2.943253          -2.877771          -3.710966   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "50          -2.988546        -2.868410        0.415123                1  \n",
       "48          -2.973726        -2.868791        0.409224                2  \n",
       "49          -2.988572        -2.868857        0.414884                3  \n",
       "32          -2.996440        -2.874761        0.447207                4  \n",
       "14          -2.996440        -2.874761        0.447207                4  \n",
       "39          -2.763140        -2.896532        0.472799                6  \n",
       "26          -2.915315        -2.898608        0.426718                7  \n",
       "8           -2.915315        -2.898608        0.426718                7  \n",
       "36          -2.844869        -2.900707        0.462890                9  \n",
       "38          -2.777924        -2.908217        0.473695               10  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values('rank_test_score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 5, 'max_features': 7, 'n_estimators': 500}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=5, max_features=7, n_estimators=500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적 선정된 모델의 Best Parameter로 GradientBoostingRegressor 생성 \n",
    "GradientBoostingRegressor(**gs.best_params_).fit(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('rf', RandomForestClassifier()), \n",
    "              ('gb', GradientBoostingClassifier())]\n",
    "\n",
    "model = StackingClassifier(estimators=estimators,\n",
    "                         final_estimator=LogisticRegression())\n",
    "\n",
    "model.fit(x_train, y_train).score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._stacking.StackingClassifier"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StackingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.6/site-packages (1.3.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from xgboost) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:18:12] WARNING: ../src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.999999003030776, 0.7476326752660457)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# 또는 \n",
    "from xgboost import XGBClassifier # 분류모델 \n",
    "from xgboost import XGBRFRegressor # 회귀모델\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "    \n",
    "boston = load_boston()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston['data'],\n",
    "                                                    boston['target'],\n",
    "                                                    random_state=0)\n",
    "# 튜닝해야 하는 파라메터가 많다\n",
    "model = xgb.XGBRegressor(objective ='reg:linear')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "p_train = model.predict(x_train)\n",
    "p_test = model.predict(x_test)\n",
    "\n",
    "r2_score(y_train, p_train), r2_score(y_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.6/site-packages (3.2.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from lightgbm) (1.19.5)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.6/site-packages (from lightgbm) (0.32.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.6/site-packages (from lightgbm) (0.24.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/dask/dataframe/utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 973\n",
      "[LightGBM] [Info] Number of data points in the train set: 379, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 22.608707\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's l2: 70.5396\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's l2: 61.4369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's l2: 53.753\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's l2: 47.6561\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's l2: 42.6525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's l2: 38.518\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's l2: 35.5033\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's l2: 33.0258\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's l2: 31.2533\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's l2: 29.944\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's l2: 28.4314\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's l2: 27.6605\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's l2: 26.7994\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's l2: 26.3312\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's l2: 25.3739\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's l2: 25.03\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's l2: 24.2976\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's l2: 24.0748\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's l2: 23.5555\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's l2: 23.5175\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's l2: 23.1308\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's l2: 23.2182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's l2: 23.3182\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's l2: 23.0598\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's l2: 23.1663\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's l2: 23.047\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's l2: 22.8929\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's l2: 22.935\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's l2: 22.8582\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's l2: 22.8969\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's l2: 22.9518\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's l2: 22.7715\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's l2: 22.5838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's l2: 22.6132\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's l2: 22.515\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's l2: 22.3831\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's l2: 22.2797\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's l2: 22.1626\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's l2: 22.0369\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's l2: 21.9226\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's l2: 21.7859\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's l2: 21.7321\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's l2: 21.592\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's l2: 21.5128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's l2: 21.5581\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's l2: 21.4947\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's l2: 21.6217\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's l2: 21.578\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's l2: 21.6729\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's l2: 21.5881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's l2: 21.7236\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's l2: 21.4947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9524522112992748, 0.7369037475494296)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston['data'],\n",
    "                                                    boston['target'],\n",
    "                                                    random_state=0)\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "}\n",
    "\n",
    "model = lgb.train(params, lgb_train, valid_sets=lgb_eval,\n",
    "                  early_stopping_rounds=5)#early_stopping_rounds은 overrfitting을 방지하기 위해 사용함!\n",
    "\n",
    "p_train = model.predict(x_train, num_iteration=model.best_iteration)\n",
    "p_test = model.predict(x_test, num_iteration=model.best_iteration)\n",
    "\n",
    "r2_score(y_train, p_train), r2_score(y_test, p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 세트 준비\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "\n",
    "# 데이터 분할\n",
    "\n",
    "\n",
    "# 모델 평가 (가장 좋은 Classification 모델을 찾아보세요.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(random_state=0),\n",
       "             param_grid={'learning_rate': [0.01, 0.01, 0.1],\n",
       "                         'max_depth': [3, 4, 5],\n",
       "                         'n_estimators': [100, 300, 500]})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "boston = load_boston()\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "params = {\n",
    "    'n_estimators' : [100, 300, 500],\n",
    "    'learning_rate' : [0.01, 0.01, 0.1],\n",
    "    'max_depth' : [3, 4, 5],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, params).fit(boston.data, boston.target)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.114536</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.622020</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.220861</td>\n",
       "      <td>0.325642</td>\n",
       "      <td>-0.175309</td>\n",
       "      <td>0.336265</td>\n",
       "      <td>0.310029</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.328283</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.865449</td>\n",
       "      <td>0.691776</td>\n",
       "      <td>0.484630</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.622589</td>\n",
       "      <td>0.197722</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.545840</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.762956</td>\n",
       "      <td>0.867336</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.535428</td>\n",
       "      <td>0.380540</td>\n",
       "      <td>0.656949</td>\n",
       "      <td>0.175110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135954</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.633338</td>\n",
       "      <td>0.626206</td>\n",
       "      <td>0.314555</td>\n",
       "      <td>0.374583</td>\n",
       "      <td>-0.250098</td>\n",
       "      <td>0.339717</td>\n",
       "      <td>0.321876</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.400393</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.756735</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.656688</td>\n",
       "      <td>0.506602</td>\n",
       "      <td>0.123035</td>\n",
       "      <td>0.570049</td>\n",
       "      <td>0.245943</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.665433</td>\n",
       "      <td>0.010462</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.768721</td>\n",
       "      <td>0.808021</td>\n",
       "      <td>0.693576</td>\n",
       "      <td>0.544797</td>\n",
       "      <td>0.224560</td>\n",
       "      <td>0.607935</td>\n",
       "      <td>0.211747</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.158405</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.634855</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>0.290091</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>-0.234089</td>\n",
       "      <td>0.325673</td>\n",
       "      <td>0.305927</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.471141</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.741932</td>\n",
       "      <td>0.763737</td>\n",
       "      <td>0.582341</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.519629</td>\n",
       "      <td>0.265394</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.782538</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.753964</td>\n",
       "      <td>0.763259</td>\n",
       "      <td>0.622998</td>\n",
       "      <td>0.498162</td>\n",
       "      <td>0.105823</td>\n",
       "      <td>0.548841</td>\n",
       "      <td>0.241819</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.110356</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.622020</td>\n",
       "      <td>0.688112</td>\n",
       "      <td>0.220861</td>\n",
       "      <td>0.325642</td>\n",
       "      <td>-0.175309</td>\n",
       "      <td>0.336265</td>\n",
       "      <td>0.310029</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.328399</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.756358</td>\n",
       "      <td>0.865449</td>\n",
       "      <td>0.691776</td>\n",
       "      <td>0.484630</td>\n",
       "      <td>0.314734</td>\n",
       "      <td>0.622589</td>\n",
       "      <td>0.197722</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.547120</td>\n",
       "      <td>0.008022</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.762956</td>\n",
       "      <td>0.867336</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.535428</td>\n",
       "      <td>0.380540</td>\n",
       "      <td>0.656949</td>\n",
       "      <td>0.175110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.134940</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.633338</td>\n",
       "      <td>0.626206</td>\n",
       "      <td>0.314555</td>\n",
       "      <td>0.374583</td>\n",
       "      <td>-0.250098</td>\n",
       "      <td>0.339717</td>\n",
       "      <td>0.321876</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.401325</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.756735</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.656688</td>\n",
       "      <td>0.506602</td>\n",
       "      <td>0.123035</td>\n",
       "      <td>0.570049</td>\n",
       "      <td>0.245943</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.666222</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 4, 'n_est...</td>\n",
       "      <td>0.768721</td>\n",
       "      <td>0.808021</td>\n",
       "      <td>0.693576</td>\n",
       "      <td>0.544797</td>\n",
       "      <td>0.224560</td>\n",
       "      <td>0.607935</td>\n",
       "      <td>0.211747</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.158078</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.634855</td>\n",
       "      <td>0.560458</td>\n",
       "      <td>0.290091</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>-0.234089</td>\n",
       "      <td>0.325673</td>\n",
       "      <td>0.305927</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.472603</td>\n",
       "      <td>0.007729</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.741932</td>\n",
       "      <td>0.763737</td>\n",
       "      <td>0.582341</td>\n",
       "      <td>0.477830</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.519629</td>\n",
       "      <td>0.265394</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.785942</td>\n",
       "      <td>0.013528</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 5, 'n_est...</td>\n",
       "      <td>0.753964</td>\n",
       "      <td>0.763259</td>\n",
       "      <td>0.622998</td>\n",
       "      <td>0.498162</td>\n",
       "      <td>0.105823</td>\n",
       "      <td>0.548841</td>\n",
       "      <td>0.241819</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.109801</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.783812</td>\n",
       "      <td>0.857255</td>\n",
       "      <td>0.742070</td>\n",
       "      <td>0.570781</td>\n",
       "      <td>0.394882</td>\n",
       "      <td>0.669760</td>\n",
       "      <td>0.166581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.328022</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.784743</td>\n",
       "      <td>0.841977</td>\n",
       "      <td>0.750611</td>\n",
       "      <td>0.554167</td>\n",
       "      <td>0.389019</td>\n",
       "      <td>0.664103</td>\n",
       "      <td>0.168187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.547035</td>\n",
       "      <td>0.008194</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 3, 'n_esti...</td>\n",
       "      <td>0.779593</td>\n",
       "      <td>0.841031</td>\n",
       "      <td>0.755053</td>\n",
       "      <td>0.552954</td>\n",
       "      <td>0.379286</td>\n",
       "      <td>0.661583</td>\n",
       "      <td>0.171089</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.134149</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.786304</td>\n",
       "      <td>0.824756</td>\n",
       "      <td>0.703891</td>\n",
       "      <td>0.579527</td>\n",
       "      <td>0.298256</td>\n",
       "      <td>0.638547</td>\n",
       "      <td>0.189767</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.402467</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.791083</td>\n",
       "      <td>0.826134</td>\n",
       "      <td>0.701348</td>\n",
       "      <td>0.554677</td>\n",
       "      <td>0.277191</td>\n",
       "      <td>0.630087</td>\n",
       "      <td>0.199827</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.670865</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 4, 'n_esti...</td>\n",
       "      <td>0.794082</td>\n",
       "      <td>0.826204</td>\n",
       "      <td>0.700705</td>\n",
       "      <td>0.550373</td>\n",
       "      <td>0.272191</td>\n",
       "      <td>0.628711</td>\n",
       "      <td>0.202375</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.158149</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.742419</td>\n",
       "      <td>0.769675</td>\n",
       "      <td>0.626869</td>\n",
       "      <td>0.534051</td>\n",
       "      <td>0.078034</td>\n",
       "      <td>0.550210</td>\n",
       "      <td>0.250678</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.474778</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.740558</td>\n",
       "      <td>0.767554</td>\n",
       "      <td>0.630651</td>\n",
       "      <td>0.526032</td>\n",
       "      <td>0.071061</td>\n",
       "      <td>0.547171</td>\n",
       "      <td>0.253007</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.789560</td>\n",
       "      <td>0.013747</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 5, 'n_esti...</td>\n",
       "      <td>0.740573</td>\n",
       "      <td>0.767495</td>\n",
       "      <td>0.630505</td>\n",
       "      <td>0.525423</td>\n",
       "      <td>0.070617</td>\n",
       "      <td>0.546923</td>\n",
       "      <td>0.253167</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.114536      0.005468         0.000666        0.000040   \n",
       "1        0.328283      0.005274         0.000947        0.000041   \n",
       "2        0.545840      0.007736         0.001223        0.000039   \n",
       "3        0.135954      0.004044         0.000706        0.000030   \n",
       "4        0.400393      0.006744         0.001178        0.000044   \n",
       "5        0.665433      0.010462         0.001522        0.000061   \n",
       "6        0.158405      0.003741         0.000815        0.000017   \n",
       "7        0.471141      0.008411         0.001430        0.000077   \n",
       "8        0.782538      0.013632         0.001951        0.000090   \n",
       "9        0.110356      0.001655         0.000638        0.000028   \n",
       "10       0.328399      0.005775         0.000939        0.000020   \n",
       "11       0.547120      0.008022         0.001219        0.000031   \n",
       "12       0.134940      0.002151         0.000714        0.000030   \n",
       "13       0.401325      0.005160         0.001164        0.000077   \n",
       "14       0.666222      0.010422         0.001502        0.000046   \n",
       "15       0.158078      0.002936         0.000783        0.000057   \n",
       "16       0.472603      0.007729         0.001466        0.000086   \n",
       "17       0.785942      0.013528         0.001995        0.000091   \n",
       "18       0.109801      0.001725         0.000650        0.000023   \n",
       "19       0.328022      0.004611         0.001003        0.000013   \n",
       "20       0.547035      0.008194         0.001282        0.000024   \n",
       "21       0.134149      0.001965         0.000754        0.000022   \n",
       "22       0.402467      0.006345         0.001191        0.000022   \n",
       "23       0.670865      0.008965         0.001558        0.000042   \n",
       "24       0.158149      0.002636         0.000837        0.000031   \n",
       "25       0.474778      0.006670         0.001383        0.000032   \n",
       "26       0.789560      0.013747         0.001845        0.000024   \n",
       "\n",
       "   param_learning_rate param_max_depth param_n_estimators  \\\n",
       "0                 0.01               3                100   \n",
       "1                 0.01               3                300   \n",
       "2                 0.01               3                500   \n",
       "3                 0.01               4                100   \n",
       "4                 0.01               4                300   \n",
       "5                 0.01               4                500   \n",
       "6                 0.01               5                100   \n",
       "7                 0.01               5                300   \n",
       "8                 0.01               5                500   \n",
       "9                 0.01               3                100   \n",
       "10                0.01               3                300   \n",
       "11                0.01               3                500   \n",
       "12                0.01               4                100   \n",
       "13                0.01               4                300   \n",
       "14                0.01               4                500   \n",
       "15                0.01               5                100   \n",
       "16                0.01               5                300   \n",
       "17                0.01               5                500   \n",
       "18                 0.1               3                100   \n",
       "19                 0.1               3                300   \n",
       "20                 0.1               3                500   \n",
       "21                 0.1               4                100   \n",
       "22                 0.1               4                300   \n",
       "23                 0.1               4                500   \n",
       "24                 0.1               5                100   \n",
       "25                 0.1               5                300   \n",
       "26                 0.1               5                500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.622020   \n",
       "1   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.756358   \n",
       "2   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.762956   \n",
       "3   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.633338   \n",
       "4   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.756735   \n",
       "5   {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.768721   \n",
       "6   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.634855   \n",
       "7   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.741932   \n",
       "8   {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.753964   \n",
       "9   {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.622020   \n",
       "10  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.756358   \n",
       "11  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...           0.762956   \n",
       "12  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.633338   \n",
       "13  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.756735   \n",
       "14  {'learning_rate': 0.01, 'max_depth': 4, 'n_est...           0.768721   \n",
       "15  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.634855   \n",
       "16  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.741932   \n",
       "17  {'learning_rate': 0.01, 'max_depth': 5, 'n_est...           0.753964   \n",
       "18  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.783812   \n",
       "19  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.784743   \n",
       "20  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...           0.779593   \n",
       "21  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.786304   \n",
       "22  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.791083   \n",
       "23  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...           0.794082   \n",
       "24  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.742419   \n",
       "25  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.740558   \n",
       "26  {'learning_rate': 0.1, 'max_depth': 5, 'n_esti...           0.740573   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.688112           0.220861           0.325642   \n",
       "1            0.865449           0.691776           0.484630   \n",
       "2            0.867336           0.738485           0.535428   \n",
       "3            0.626206           0.314555           0.374583   \n",
       "4            0.807186           0.656688           0.506602   \n",
       "5            0.808021           0.693576           0.544797   \n",
       "6            0.560458           0.290091           0.377049   \n",
       "7            0.763737           0.582341           0.477830   \n",
       "8            0.763259           0.622998           0.498162   \n",
       "9            0.688112           0.220861           0.325642   \n",
       "10           0.865449           0.691776           0.484630   \n",
       "11           0.867336           0.738485           0.535428   \n",
       "12           0.626206           0.314555           0.374583   \n",
       "13           0.807186           0.656688           0.506602   \n",
       "14           0.808021           0.693576           0.544797   \n",
       "15           0.560458           0.290091           0.377049   \n",
       "16           0.763737           0.582341           0.477830   \n",
       "17           0.763259           0.622998           0.498162   \n",
       "18           0.857255           0.742070           0.570781   \n",
       "19           0.841977           0.750611           0.554167   \n",
       "20           0.841031           0.755053           0.552954   \n",
       "21           0.824756           0.703891           0.579527   \n",
       "22           0.826134           0.701348           0.554677   \n",
       "23           0.826204           0.700705           0.550373   \n",
       "24           0.769675           0.626869           0.534051   \n",
       "25           0.767554           0.630651           0.526032   \n",
       "26           0.767495           0.630505           0.525423   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           -0.175309         0.336265        0.310029               24  \n",
       "1            0.314734         0.622589        0.197722                9  \n",
       "2            0.380540         0.656949        0.175110                4  \n",
       "3           -0.250098         0.339717        0.321876               22  \n",
       "4            0.123035         0.570049        0.245943               13  \n",
       "5            0.224560         0.607935        0.211747               11  \n",
       "6           -0.234089         0.325673        0.305927               26  \n",
       "7            0.032308         0.519629        0.265394               20  \n",
       "8            0.105823         0.548841        0.241819               16  \n",
       "9           -0.175309         0.336265        0.310029               24  \n",
       "10           0.314734         0.622589        0.197722                9  \n",
       "11           0.380540         0.656949        0.175110                4  \n",
       "12          -0.250098         0.339717        0.321876               22  \n",
       "13           0.123035         0.570049        0.245943               13  \n",
       "14           0.224560         0.607935        0.211747               11  \n",
       "15          -0.234089         0.325673        0.305927               26  \n",
       "16           0.032308         0.519629        0.265394               20  \n",
       "17           0.105823         0.548841        0.241819               16  \n",
       "18           0.394882         0.669760        0.166581                1  \n",
       "19           0.389019         0.664103        0.168187                2  \n",
       "20           0.379286         0.661583        0.171089                3  \n",
       "21           0.298256         0.638547        0.189767                6  \n",
       "22           0.277191         0.630087        0.199827                7  \n",
       "23           0.272191         0.628711        0.202375                8  \n",
       "24           0.078034         0.550210        0.250678               15  \n",
       "25           0.071061         0.547171        0.253007               18  \n",
       "26           0.070617         0.546923        0.253167               19  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "report = pd.DataFrame(gs.cv_results_)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6697600256867121"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(random_state=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
